{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request \n",
    "from urllib.request import urlopen \n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "https://www.rottentomatoes.com/sitemap_1.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = set() \n",
    "\n",
    "rootpage = 'https://www.rottentomatoes.com/sitemap_' \n",
    "end = '.xml'\n",
    "\n",
    "def getLinks(pageUrl):\n",
    "    global pages \n",
    "    for sitemap_page in range(26, 28): \n",
    "        html = urlopen(rootpage+str(sitemap_page)+end)\n",
    "        bsObj = BeautifulSoup(html)\n",
    "        \n",
    "        for link in bsObj.findAll('loc'):\n",
    "            link = str(link).replace('</loc>', '').split('.com')\n",
    "            \n",
    "            if link[1] not in pages: \n",
    "                pages.add(link[1])\n",
    "                \n",
    "getLinks('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [] \n",
    "for movie in pages: \n",
    "    sites.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/m/catching_out/pictures/\n"
     ]
    }
   ],
   "source": [
    "print(sites[89306])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitelist = []\n",
    "for s in sitesoup('loc'):\n",
    "    s = s.extract()\n",
    "    s = str(s).replace('<loc>', '').replace('</loc>', '')\n",
    "    sitelist.append(s)\n",
    "\n",
    "sitelist = sitelist[3:5]\n",
    "\n",
    "for n in sitelist:  \n",
    "    n = requests.get(n)\n",
    "    n_soup = BeautifulSoup(n.text, 'lxml')\n",
    "\n",
    "site_ns = []\n",
    "\n",
    "for mvs in n_soup('loc'):\n",
    "    mvs = mvs.extract()\n",
    "    mvs = str(mvs).replace('<loc>', '').replace('</loc>', '')\n",
    "    \n",
    "    site_ns.append(mvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(site_ns)\n",
    "site_ns_short = []\n",
    "\n",
    "len_sitens = len(site_ns)\n",
    "\n",
    "for mv in range(len_sitens): \n",
    "    short = site_ns[mv].split('.com')[1].split('/pictures/')[0].split('/trailers/')[0]\n",
    "    site_ns_short.append(short)\n",
    "\n",
    "site_ns_short = list(dict.fromkeys(site_ns_short))\n",
    "print(site_ns_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://www.rottentomatoes.com'\n",
    "listlength = len(site_ns_short)\n",
    "movie_df = pd.DataFrame(columns=['title', 'tomatoScore', 'popcornScore', 'siteurl', 'imagePoster'])\n",
    "\n",
    "for movie in range(listlength-1):  \n",
    "    try:\n",
    "    \n",
    "        url = site_ns_short[movie]\n",
    "        #print(url)\n",
    "        siteurl = baseurl+url\n",
    "        print(siteurl)\n",
    "\n",
    "        #peek at movie url\n",
    "        response = requests.get(siteurl)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text_response = response.text\n",
    "        #print(text_response)\n",
    "\n",
    "        #get title \n",
    "        movie_title = text_response.split('\"name\":\"')[1].split('\"')[0]\n",
    "\n",
    "        #get tomato score\n",
    "        tomatoScore = text_response.split('ratingValue\":')[1].split(',\"')[0]\n",
    "\n",
    "        #get audience score \n",
    "        ems_id = text_response.split('emsId\":\"')[1].split('\"')[0]\n",
    "        ems_req_url = f'https://www.rottentomatoes.com/napi/audienceScore/{ems_id}'\n",
    "\n",
    "        ems_response = requests.get(ems_req_url)\n",
    "        ems_soup = BeautifulSoup(ems_response.text, 'html.parser')\n",
    "        ems_text_response = ems_response.text\n",
    "        json_ems = json.loads(ems_text_response)\n",
    "        popcornScore = json_ems['audienceScoreAll']['score']\n",
    "\n",
    "        #print(f'Looking up Rotten Tomatoes Score for: {siteurl}')\n",
    "        #print(f'Movie Title: {movie_title}')\n",
    "        #print(f'Tomato Score: {tomatoScore}')\n",
    "        #print(f'Popcorn Score: {popcornScore}')\n",
    "\n",
    "        movie_df.loc[movie] = [movie_title, tomatoScore, popcornScore, siteurl, imagePoster]\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df_copy = movie_df.replace('null', popcornScore)\n",
    "       \n",
    "movie_df_copy['squidScore'] = (movie_df_copy['popcornScore'].astype(int)-movie_df_copy['tomatoScore'].astype(int))\n",
    "movie_df_copy.sort_values(by=['squidScore'], ascending=False )\n",
    "\n",
    "#print(f'Might sloth suggest: {movieChoice[1]}')\n",
    "#movie_df_copy.to_csv('movies_sitelist678910', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
